{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.keras as keras\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use saved data from problem 2a\n",
    "dataset = pd.read_csv('output_data.csv')\n",
    "X = dataset.iloc[:,[1,2]].values\n",
    "y = dataset.iloc[:,3].values\n",
    "assert(X.shape[0] == 2000)\n",
    "assert(X.shape[1] == 2)\n",
    "assert(y.shape[0] == 2000)\n",
    "\n",
    "#The train-test split to be used for the dataset is 80%-20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "#Mean centering and normalization\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train)\n",
    "\n",
    "X_trainc = (X_train - mean)/std\n",
    "X_testc = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/300\n",
      "1440/1440 [==============================] - 1s 917us/sample - loss: 2.9668 - accuracy: 0.0826 - val_loss: 2.9720 - val_accuracy: 0.0750\n",
      "Epoch 2/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 2.9380 - accuracy: 0.1000 - val_loss: 2.9482 - val_accuracy: 0.0750\n",
      "Epoch 3/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 2.9110 - accuracy: 0.1007 - val_loss: 2.9255 - val_accuracy: 0.0938\n",
      "Epoch 4/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 2.8852 - accuracy: 0.1056 - val_loss: 2.9035 - val_accuracy: 0.1063\n",
      "Epoch 5/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 2.8592 - accuracy: 0.1160 - val_loss: 2.8817 - val_accuracy: 0.1187\n",
      "Epoch 6/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 2.8344 - accuracy: 0.1250 - val_loss: 2.8603 - val_accuracy: 0.1187\n",
      "Epoch 7/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 2.8095 - accuracy: 0.1257 - val_loss: 2.8394 - val_accuracy: 0.1187\n",
      "Epoch 8/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 2.7845 - accuracy: 0.1278 - val_loss: 2.8164 - val_accuracy: 0.1187\n",
      "Epoch 9/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 2.7587 - accuracy: 0.1306 - val_loss: 2.7935 - val_accuracy: 0.1187\n",
      "Epoch 10/300\n",
      "1440/1440 [==============================] - 0s 150us/sample - loss: 2.7326 - accuracy: 0.1312 - val_loss: 2.7703 - val_accuracy: 0.1250\n",
      "Epoch 11/300\n",
      "1440/1440 [==============================] - 0s 135us/sample - loss: 2.7063 - accuracy: 0.1361 - val_loss: 2.7464 - val_accuracy: 0.1250\n",
      "Epoch 12/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 2.6800 - accuracy: 0.1382 - val_loss: 2.7220 - val_accuracy: 0.1250\n",
      "Epoch 13/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 2.6539 - accuracy: 0.1403 - val_loss: 2.6973 - val_accuracy: 0.1250\n",
      "Epoch 14/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 2.6275 - accuracy: 0.1424 - val_loss: 2.6723 - val_accuracy: 0.1312\n",
      "Epoch 15/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 2.6011 - accuracy: 0.1444 - val_loss: 2.6460 - val_accuracy: 0.1375\n",
      "Epoch 16/300\n",
      "1440/1440 [==============================] - 0s 146us/sample - loss: 2.5746 - accuracy: 0.1472 - val_loss: 2.6208 - val_accuracy: 0.1375\n",
      "Epoch 17/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 2.5485 - accuracy: 0.1486 - val_loss: 2.5936 - val_accuracy: 0.1375\n",
      "Epoch 18/300\n",
      "1440/1440 [==============================] - 0s 134us/sample - loss: 2.5222 - accuracy: 0.1500 - val_loss: 2.5671 - val_accuracy: 0.1375\n",
      "Epoch 19/300\n",
      "1440/1440 [==============================] - 0s 138us/sample - loss: 2.4964 - accuracy: 0.1514 - val_loss: 2.5398 - val_accuracy: 0.1437\n",
      "Epoch 20/300\n",
      "1440/1440 [==============================] - 0s 137us/sample - loss: 2.4710 - accuracy: 0.1514 - val_loss: 2.5129 - val_accuracy: 0.1437\n",
      "Epoch 21/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 2.4464 - accuracy: 0.1514 - val_loss: 2.4872 - val_accuracy: 0.1375\n",
      "Epoch 22/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 2.4224 - accuracy: 0.1514 - val_loss: 2.4607 - val_accuracy: 0.1375\n",
      "Epoch 23/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 2.3989 - accuracy: 0.1514 - val_loss: 2.4358 - val_accuracy: 0.1375\n",
      "Epoch 24/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 2.3765 - accuracy: 0.1500 - val_loss: 2.4102 - val_accuracy: 0.1375\n",
      "Epoch 25/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 2.3545 - accuracy: 0.1514 - val_loss: 2.3858 - val_accuracy: 0.1375\n",
      "Epoch 26/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 2.3334 - accuracy: 0.1583 - val_loss: 2.3621 - val_accuracy: 0.1562\n",
      "Epoch 27/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 2.3131 - accuracy: 0.1507 - val_loss: 2.3398 - val_accuracy: 0.1625\n",
      "Epoch 28/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 2.2936 - accuracy: 0.1562 - val_loss: 2.3182 - val_accuracy: 0.1375\n",
      "Epoch 29/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 2.2749 - accuracy: 0.1472 - val_loss: 2.2955 - val_accuracy: 0.1625\n",
      "Epoch 30/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 2.2566 - accuracy: 0.1549 - val_loss: 2.2753 - val_accuracy: 0.1375\n",
      "Epoch 31/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 2.2384 - accuracy: 0.1562 - val_loss: 2.2549 - val_accuracy: 0.1375\n",
      "Epoch 32/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 2.2212 - accuracy: 0.1562 - val_loss: 2.2350 - val_accuracy: 0.1375\n",
      "Epoch 33/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 2.2035 - accuracy: 0.1576 - val_loss: 2.2158 - val_accuracy: 0.1375\n",
      "Epoch 34/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 2.1868 - accuracy: 0.1632 - val_loss: 2.1966 - val_accuracy: 0.1500\n",
      "Epoch 35/300\n",
      "1440/1440 [==============================] - 0s 174us/sample - loss: 2.1705 - accuracy: 0.1653 - val_loss: 2.1776 - val_accuracy: 0.1500\n",
      "Epoch 36/300\n",
      "1440/1440 [==============================] - 0s 167us/sample - loss: 2.1539 - accuracy: 0.1688 - val_loss: 2.1589 - val_accuracy: 0.1562\n",
      "Epoch 37/300\n",
      "1440/1440 [==============================] - 0s 150us/sample - loss: 2.1382 - accuracy: 0.1813 - val_loss: 2.1421 - val_accuracy: 0.1813\n",
      "Epoch 38/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 2.1225 - accuracy: 0.1944 - val_loss: 2.1238 - val_accuracy: 0.2188\n",
      "Epoch 39/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 2.1068 - accuracy: 0.2125 - val_loss: 2.1055 - val_accuracy: 0.2438\n",
      "Epoch 40/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 2.0921 - accuracy: 0.2597 - val_loss: 2.0887 - val_accuracy: 0.2500\n",
      "Epoch 41/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 2.0769 - accuracy: 0.2319 - val_loss: 2.0740 - val_accuracy: 0.2625\n",
      "Epoch 42/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 2.0621 - accuracy: 0.2986 - val_loss: 2.0572 - val_accuracy: 0.2750\n",
      "Epoch 43/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 2.0475 - accuracy: 0.2806 - val_loss: 2.0397 - val_accuracy: 0.3375\n",
      "Epoch 44/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 2.0324 - accuracy: 0.2944 - val_loss: 2.0233 - val_accuracy: 0.3125\n",
      "Epoch 45/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 2.0179 - accuracy: 0.3208 - val_loss: 2.0079 - val_accuracy: 0.3438\n",
      "Epoch 46/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 2.0040 - accuracy: 0.3278 - val_loss: 1.9912 - val_accuracy: 0.2937\n",
      "Epoch 47/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.9888 - accuracy: 0.3285 - val_loss: 1.9764 - val_accuracy: 0.3812\n",
      "Epoch 48/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.9740 - accuracy: 0.3722 - val_loss: 1.9610 - val_accuracy: 0.3875\n",
      "Epoch 49/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 1.9600 - accuracy: 0.3667 - val_loss: 1.9446 - val_accuracy: 0.3812\n",
      "Epoch 50/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 1.9453 - accuracy: 0.3528 - val_loss: 1.9282 - val_accuracy: 0.3875\n",
      "Epoch 51/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 1.9301 - accuracy: 0.3903 - val_loss: 1.9115 - val_accuracy: 0.4062\n",
      "Epoch 52/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 1.9157 - accuracy: 0.3535 - val_loss: 1.8962 - val_accuracy: 0.3812\n",
      "Epoch 53/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.9011 - accuracy: 0.3889 - val_loss: 1.8809 - val_accuracy: 0.3875\n",
      "Epoch 54/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 1.8872 - accuracy: 0.3729 - val_loss: 1.8654 - val_accuracy: 0.4000\n",
      "Epoch 55/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.8731 - accuracy: 0.4007 - val_loss: 1.8509 - val_accuracy: 0.4125\n",
      "Epoch 56/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 1.8588 - accuracy: 0.3924 - val_loss: 1.8359 - val_accuracy: 0.3625\n",
      "Epoch 57/300\n",
      "1440/1440 [==============================] - 0s 171us/sample - loss: 1.8446 - accuracy: 0.3799 - val_loss: 1.8234 - val_accuracy: 0.4313\n",
      "Epoch 58/300\n",
      "1440/1440 [==============================] - 0s 151us/sample - loss: 1.8315 - accuracy: 0.3812 - val_loss: 1.8066 - val_accuracy: 0.4250\n",
      "Epoch 59/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 1.8170 - accuracy: 0.3958 - val_loss: 1.7924 - val_accuracy: 0.4125\n",
      "Epoch 60/300\n",
      "1440/1440 [==============================] - 0s 135us/sample - loss: 1.8043 - accuracy: 0.4167 - val_loss: 1.7802 - val_accuracy: 0.4437\n",
      "Epoch 61/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.7925 - accuracy: 0.4437 - val_loss: 1.7655 - val_accuracy: 0.4375\n",
      "Epoch 62/300\n",
      "1440/1440 [==============================] - 0s 161us/sample - loss: 1.7765 - accuracy: 0.4583 - val_loss: 1.7500 - val_accuracy: 0.4250\n",
      "Epoch 63/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 1.7638 - accuracy: 0.4444 - val_loss: 1.7383 - val_accuracy: 0.4313\n",
      "Epoch 64/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 1.7513 - accuracy: 0.4778 - val_loss: 1.7232 - val_accuracy: 0.4938\n",
      "Epoch 65/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.7375 - accuracy: 0.4444 - val_loss: 1.7104 - val_accuracy: 0.4187\n",
      "Epoch 66/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.7250 - accuracy: 0.4500 - val_loss: 1.6966 - val_accuracy: 0.4750\n",
      "Epoch 67/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 1.7118 - accuracy: 0.4910 - val_loss: 1.6822 - val_accuracy: 0.4938\n",
      "Epoch 68/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.7006 - accuracy: 0.5063 - val_loss: 1.6689 - val_accuracy: 0.4375\n",
      "Epoch 69/300\n",
      "1440/1440 [==============================] - 0s 109us/sample - loss: 1.6875 - accuracy: 0.4882 - val_loss: 1.6579 - val_accuracy: 0.4875\n",
      "Epoch 70/300\n",
      "1440/1440 [==============================] - 0s 110us/sample - loss: 1.6748 - accuracy: 0.4639 - val_loss: 1.6448 - val_accuracy: 0.5312\n",
      "Epoch 71/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.6635 - accuracy: 0.4965 - val_loss: 1.6306 - val_accuracy: 0.5000\n",
      "Epoch 72/300\n",
      "1440/1440 [==============================] - 0s 162us/sample - loss: 1.6519 - accuracy: 0.5500 - val_loss: 1.6201 - val_accuracy: 0.5188\n",
      "Epoch 73/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 1.6392 - accuracy: 0.5431 - val_loss: 1.6100 - val_accuracy: 0.4938\n",
      "Epoch 74/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 1.6270 - accuracy: 0.5285 - val_loss: 1.5949 - val_accuracy: 0.5000\n",
      "Epoch 75/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.6168 - accuracy: 0.5271 - val_loss: 1.5847 - val_accuracy: 0.5625\n",
      "Epoch 76/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.6049 - accuracy: 0.5312 - val_loss: 1.5727 - val_accuracy: 0.5063\n",
      "Epoch 77/300\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 0.58 - 0s 131us/sample - loss: 1.5927 - accuracy: 0.5840 - val_loss: 1.5631 - val_accuracy: 0.5375\n",
      "Epoch 78/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.5807 - accuracy: 0.6028 - val_loss: 1.5484 - val_accuracy: 0.5688\n",
      "Epoch 79/300\n",
      "1440/1440 [==============================] - 0s 129us/sample - loss: 1.5701 - accuracy: 0.5472 - val_loss: 1.5362 - val_accuracy: 0.5437\n",
      "Epoch 80/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.5579 - accuracy: 0.5965 - val_loss: 1.5281 - val_accuracy: 0.5188\n",
      "Epoch 81/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 1.5491 - accuracy: 0.5819 - val_loss: 1.5178 - val_accuracy: 0.6187\n",
      "Epoch 82/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 1.5364 - accuracy: 0.5583 - val_loss: 1.5052 - val_accuracy: 0.5875\n",
      "Epoch 83/300\n",
      "1440/1440 [==============================] - 0s 137us/sample - loss: 1.5265 - accuracy: 0.5951 - val_loss: 1.4939 - val_accuracy: 0.5562\n",
      "Epoch 84/300\n",
      "1440/1440 [==============================] - 0s 130us/sample - loss: 1.5167 - accuracy: 0.6014 - val_loss: 1.4848 - val_accuracy: 0.6187\n",
      "Epoch 85/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.5053 - accuracy: 0.6285 - val_loss: 1.4741 - val_accuracy: 0.5562\n",
      "Epoch 86/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.4945 - accuracy: 0.5986 - val_loss: 1.4631 - val_accuracy: 0.5312\n",
      "Epoch 87/300\n",
      "1440/1440 [==============================] - 0s 162us/sample - loss: 1.4847 - accuracy: 0.5938 - val_loss: 1.4551 - val_accuracy: 0.6062\n",
      "Epoch 88/300\n",
      "1440/1440 [==============================] - 0s 141us/sample - loss: 1.4765 - accuracy: 0.6083 - val_loss: 1.4452 - val_accuracy: 0.5875\n",
      "Epoch 89/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.4656 - accuracy: 0.6375 - val_loss: 1.4320 - val_accuracy: 0.5813\n",
      "Epoch 90/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 1.4559 - accuracy: 0.6111 - val_loss: 1.4248 - val_accuracy: 0.6500\n",
      "Epoch 91/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.4452 - accuracy: 0.6056 - val_loss: 1.4143 - val_accuracy: 0.6187\n",
      "Epoch 92/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.4372 - accuracy: 0.6840 - val_loss: 1.3996 - val_accuracy: 0.6250\n",
      "Epoch 93/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.4273 - accuracy: 0.5986 - val_loss: 1.3944 - val_accuracy: 0.6438\n",
      "Epoch 94/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.4187 - accuracy: 0.6542 - val_loss: 1.3825 - val_accuracy: 0.6438\n",
      "Epoch 95/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.4091 - accuracy: 0.6313 - val_loss: 1.3791 - val_accuracy: 0.6062\n",
      "Epoch 96/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.3997 - accuracy: 0.6694 - val_loss: 1.3680 - val_accuracy: 0.6438\n",
      "Epoch 97/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.3908 - accuracy: 0.6653 - val_loss: 1.3579 - val_accuracy: 0.6500\n",
      "Epoch 98/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.3814 - accuracy: 0.6438 - val_loss: 1.3504 - val_accuracy: 0.5813\n",
      "Epoch 99/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.3720 - accuracy: 0.6306 - val_loss: 1.3415 - val_accuracy: 0.6313\n",
      "Epoch 100/300\n",
      "1440/1440 [==============================] - 0s 140us/sample - loss: 1.3629 - accuracy: 0.7000 - val_loss: 1.3294 - val_accuracy: 0.6187\n",
      "Epoch 101/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.3555 - accuracy: 0.6292 - val_loss: 1.3249 - val_accuracy: 0.6812\n",
      "Epoch 102/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.3476 - accuracy: 0.6736 - val_loss: 1.3131 - val_accuracy: 0.6313\n",
      "Epoch 103/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.3386 - accuracy: 0.6562 - val_loss: 1.3060 - val_accuracy: 0.6625\n",
      "Epoch 104/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.3300 - accuracy: 0.6632 - val_loss: 1.2977 - val_accuracy: 0.6938\n",
      "Epoch 105/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 1.3226 - accuracy: 0.7028 - val_loss: 1.2873 - val_accuracy: 0.7250\n",
      "Epoch 106/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.3132 - accuracy: 0.6847 - val_loss: 1.2808 - val_accuracy: 0.6687\n",
      "Epoch 107/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.3062 - accuracy: 0.6569 - val_loss: 1.2778 - val_accuracy: 0.6938\n",
      "Epoch 108/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 1.2992 - accuracy: 0.6722 - val_loss: 1.2643 - val_accuracy: 0.6625\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.2894 - accuracy: 0.6743 - val_loss: 1.2602 - val_accuracy: 0.6187\n",
      "Epoch 110/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.2827 - accuracy: 0.6924 - val_loss: 1.2535 - val_accuracy: 0.6750\n",
      "Epoch 111/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.2758 - accuracy: 0.6715 - val_loss: 1.2430 - val_accuracy: 0.7188\n",
      "Epoch 112/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.2655 - accuracy: 0.7139 - val_loss: 1.2318 - val_accuracy: 0.6438\n",
      "Epoch 113/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 1.2587 - accuracy: 0.6944 - val_loss: 1.2272 - val_accuracy: 0.6938\n",
      "Epoch 114/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.2521 - accuracy: 0.7167 - val_loss: 1.2168 - val_accuracy: 0.7250\n",
      "Epoch 115/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.2446 - accuracy: 0.7076 - val_loss: 1.2135 - val_accuracy: 0.6438\n",
      "Epoch 116/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.2377 - accuracy: 0.7097 - val_loss: 1.2019 - val_accuracy: 0.6875\n",
      "Epoch 117/300\n",
      "1440/1440 [==============================] - 0s 129us/sample - loss: 1.2317 - accuracy: 0.6986 - val_loss: 1.1968 - val_accuracy: 0.7125\n",
      "Epoch 118/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.2238 - accuracy: 0.7479 - val_loss: 1.1936 - val_accuracy: 0.6875\n",
      "Epoch 119/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.2169 - accuracy: 0.7021 - val_loss: 1.1839 - val_accuracy: 0.6750\n",
      "Epoch 120/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.2080 - accuracy: 0.7118 - val_loss: 1.1746 - val_accuracy: 0.7000\n",
      "Epoch 121/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 1.2015 - accuracy: 0.7264 - val_loss: 1.1731 - val_accuracy: 0.7250\n",
      "Epoch 122/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.1946 - accuracy: 0.7465 - val_loss: 1.1619 - val_accuracy: 0.6812\n",
      "Epoch 123/300\n",
      "1440/1440 [==============================] - 0s 155us/sample - loss: 1.1899 - accuracy: 0.7125 - val_loss: 1.1539 - val_accuracy: 0.7125\n",
      "Epoch 124/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.1811 - accuracy: 0.7160 - val_loss: 1.1476 - val_accuracy: 0.7188\n",
      "Epoch 125/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.1757 - accuracy: 0.7333 - val_loss: 1.1412 - val_accuracy: 0.6875\n",
      "Epoch 126/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 1.1689 - accuracy: 0.7035 - val_loss: 1.1342 - val_accuracy: 0.7125\n",
      "Epoch 127/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.1627 - accuracy: 0.7104 - val_loss: 1.1310 - val_accuracy: 0.7750\n",
      "Epoch 128/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.1575 - accuracy: 0.7174 - val_loss: 1.1223 - val_accuracy: 0.7000\n",
      "Epoch 129/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.1524 - accuracy: 0.6812 - val_loss: 1.1135 - val_accuracy: 0.7375\n",
      "Epoch 130/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.1450 - accuracy: 0.7132 - val_loss: 1.1138 - val_accuracy: 0.7625\n",
      "Epoch 131/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.1385 - accuracy: 0.7472 - val_loss: 1.1044 - val_accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 1.1320 - accuracy: 0.7153 - val_loss: 1.0947 - val_accuracy: 0.7875\n",
      "Epoch 133/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.1250 - accuracy: 0.7410 - val_loss: 1.0887 - val_accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.1177 - accuracy: 0.7382 - val_loss: 1.0909 - val_accuracy: 0.7250\n",
      "Epoch 135/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.1117 - accuracy: 0.7389 - val_loss: 1.0767 - val_accuracy: 0.7437\n",
      "Epoch 136/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.1070 - accuracy: 0.7042 - val_loss: 1.0768 - val_accuracy: 0.7563\n",
      "Epoch 137/300\n",
      "1440/1440 [==============================] - 0s 132us/sample - loss: 1.1000 - accuracy: 0.7479 - val_loss: 1.0698 - val_accuracy: 0.7375\n",
      "Epoch 138/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 1.0943 - accuracy: 0.7194 - val_loss: 1.0653 - val_accuracy: 0.7437\n",
      "Epoch 139/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 1.0899 - accuracy: 0.7104 - val_loss: 1.0589 - val_accuracy: 0.7437\n",
      "Epoch 140/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 1.0849 - accuracy: 0.7361 - val_loss: 1.0533 - val_accuracy: 0.7437\n",
      "Epoch 141/300\n",
      "1440/1440 [==============================] - 0s 129us/sample - loss: 1.0768 - accuracy: 0.7424 - val_loss: 1.0432 - val_accuracy: 0.7812\n",
      "Epoch 142/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 1.0715 - accuracy: 0.7736 - val_loss: 1.0397 - val_accuracy: 0.7375\n",
      "Epoch 143/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 1.0671 - accuracy: 0.7771 - val_loss: 1.0338 - val_accuracy: 0.8188\n",
      "Epoch 144/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 1.0602 - accuracy: 0.7819 - val_loss: 1.0296 - val_accuracy: 0.8000\n",
      "Epoch 145/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.0571 - accuracy: 0.7563 - val_loss: 1.0244 - val_accuracy: 0.7437\n",
      "Epoch 146/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 1.0508 - accuracy: 0.7576 - val_loss: 1.0156 - val_accuracy: 0.7500\n",
      "Epoch 147/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 1.0444 - accuracy: 0.7382 - val_loss: 1.0141 - val_accuracy: 0.7625\n",
      "Epoch 148/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.0398 - accuracy: 0.7604 - val_loss: 1.0070 - val_accuracy: 0.7437\n",
      "Epoch 149/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 1.0326 - accuracy: 0.7382 - val_loss: 1.0030 - val_accuracy: 0.7625\n",
      "Epoch 150/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.0301 - accuracy: 0.7417 - val_loss: 0.9987 - val_accuracy: 0.7688\n",
      "Epoch 151/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 1.0234 - accuracy: 0.7660 - val_loss: 0.9945 - val_accuracy: 0.7750\n",
      "Epoch 152/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 1.0175 - accuracy: 0.8014 - val_loss: 0.9846 - val_accuracy: 0.7875\n",
      "Epoch 153/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 1.0115 - accuracy: 0.7437 - val_loss: 0.9844 - val_accuracy: 0.7563\n",
      "Epoch 154/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 1.0052 - accuracy: 0.7576 - val_loss: 0.9725 - val_accuracy: 0.6938\n",
      "Epoch 155/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 1.0028 - accuracy: 0.7625 - val_loss: 0.9741 - val_accuracy: 0.7812\n",
      "Epoch 156/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 0.9963 - accuracy: 0.7847 - val_loss: 0.9606 - val_accuracy: 0.7937\n",
      "Epoch 157/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.9907 - accuracy: 0.7937 - val_loss: 0.9621 - val_accuracy: 0.7563\n",
      "Epoch 158/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.9890 - accuracy: 0.7667 - val_loss: 0.9524 - val_accuracy: 0.8062\n",
      "Epoch 159/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.9805 - accuracy: 0.7924 - val_loss: 0.9470 - val_accuracy: 0.7937\n",
      "Epoch 160/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.9747 - accuracy: 0.7736 - val_loss: 0.9496 - val_accuracy: 0.7937\n",
      "Epoch 161/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.9735 - accuracy: 0.7535 - val_loss: 0.9393 - val_accuracy: 0.7188\n",
      "Epoch 162/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 0.9662 - accuracy: 0.7604 - val_loss: 0.9328 - val_accuracy: 0.7375\n",
      "Epoch 163/300\n",
      "1440/1440 [==============================] - 0s 151us/sample - loss: 0.9618 - accuracy: 0.7674 - val_loss: 0.9227 - val_accuracy: 0.8125\n",
      "Epoch 164/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.9560 - accuracy: 0.7785 - val_loss: 0.9254 - val_accuracy: 0.7688\n",
      "Epoch 165/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.9515 - accuracy: 0.7799 - val_loss: 0.9204 - val_accuracy: 0.7937\n",
      "Epoch 166/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.9473 - accuracy: 0.7819 - val_loss: 0.9198 - val_accuracy: 0.7375\n",
      "Epoch 167/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 0.9402 - accuracy: 0.7924 - val_loss: 0.9098 - val_accuracy: 0.7750\n",
      "Epoch 168/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.9380 - accuracy: 0.7667 - val_loss: 0.9059 - val_accuracy: 0.8188\n",
      "Epoch 169/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 0.9315 - accuracy: 0.8056 - val_loss: 0.9015 - val_accuracy: 0.7750\n",
      "Epoch 170/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.9284 - accuracy: 0.7799 - val_loss: 0.8966 - val_accuracy: 0.8062\n",
      "Epoch 171/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 0.9203 - accuracy: 0.7903 - val_loss: 0.8914 - val_accuracy: 0.7625\n",
      "Epoch 172/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.9204 - accuracy: 0.7812 - val_loss: 0.8880 - val_accuracy: 0.7437\n",
      "Epoch 173/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.9125 - accuracy: 0.7931 - val_loss: 0.8843 - val_accuracy: 0.8062\n",
      "Epoch 174/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.9075 - accuracy: 0.7757 - val_loss: 0.8802 - val_accuracy: 0.7750\n",
      "Epoch 175/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.9060 - accuracy: 0.7514 - val_loss: 0.8725 - val_accuracy: 0.8000\n",
      "Epoch 176/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 0.9002 - accuracy: 0.7924 - val_loss: 0.8692 - val_accuracy: 0.8062\n",
      "Epoch 177/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 0.8941 - accuracy: 0.8153 - val_loss: 0.8632 - val_accuracy: 0.7937\n",
      "Epoch 178/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.8879 - accuracy: 0.7840 - val_loss: 0.8593 - val_accuracy: 0.7750\n",
      "Epoch 179/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.8815 - accuracy: 0.7958 - val_loss: 0.8602 - val_accuracy: 0.8188\n",
      "Epoch 180/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.8809 - accuracy: 0.8111 - val_loss: 0.8573 - val_accuracy: 0.7937\n",
      "Epoch 181/300\n",
      "1440/1440 [==============================] - 0s 146us/sample - loss: 0.8773 - accuracy: 0.7646 - val_loss: 0.8455 - val_accuracy: 0.8313\n",
      "Epoch 182/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.8725 - accuracy: 0.8014 - val_loss: 0.8410 - val_accuracy: 0.7688\n",
      "Epoch 183/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.8673 - accuracy: 0.8139 - val_loss: 0.8467 - val_accuracy: 0.8125\n",
      "Epoch 184/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 0.8598 - accuracy: 0.8333 - val_loss: 0.8313 - val_accuracy: 0.8500\n",
      "Epoch 185/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 0.8552 - accuracy: 0.7993 - val_loss: 0.8255 - val_accuracy: 0.8062\n",
      "Epoch 186/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 0.8507 - accuracy: 0.8000 - val_loss: 0.8254 - val_accuracy: 0.7750\n",
      "Epoch 187/300\n",
      "1440/1440 [==============================] - 0s 142us/sample - loss: 0.8468 - accuracy: 0.7972 - val_loss: 0.8201 - val_accuracy: 0.7750\n",
      "Epoch 188/300\n",
      "1440/1440 [==============================] - 0s 142us/sample - loss: 0.8474 - accuracy: 0.7778 - val_loss: 0.8158 - val_accuracy: 0.7250\n",
      "Epoch 189/300\n",
      "1440/1440 [==============================] - 0s 129us/sample - loss: 0.8421 - accuracy: 0.7701 - val_loss: 0.8103 - val_accuracy: 0.8375\n",
      "Epoch 190/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.8365 - accuracy: 0.8021 - val_loss: 0.8016 - val_accuracy: 0.8438\n",
      "Epoch 191/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.8278 - accuracy: 0.8021 - val_loss: 0.8005 - val_accuracy: 0.7937\n",
      "Epoch 192/300\n",
      "1440/1440 [==============================] - 0s 110us/sample - loss: 0.8245 - accuracy: 0.8007 - val_loss: 0.7979 - val_accuracy: 0.8313\n",
      "Epoch 193/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.8234 - accuracy: 0.8083 - val_loss: 0.8016 - val_accuracy: 0.7625\n",
      "Epoch 194/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.8178 - accuracy: 0.7944 - val_loss: 0.7957 - val_accuracy: 0.8188\n",
      "Epoch 195/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.8176 - accuracy: 0.8062 - val_loss: 0.7929 - val_accuracy: 0.8000\n",
      "Epoch 196/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.8061 - accuracy: 0.8153 - val_loss: 0.7857 - val_accuracy: 0.7625\n",
      "Epoch 197/300\n",
      "1440/1440 [==============================] - 0s 130us/sample - loss: 0.8067 - accuracy: 0.7979 - val_loss: 0.7744 - val_accuracy: 0.8125\n",
      "Epoch 198/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.7988 - accuracy: 0.8069 - val_loss: 0.7705 - val_accuracy: 0.8188\n",
      "Epoch 199/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.7930 - accuracy: 0.8021 - val_loss: 0.7736 - val_accuracy: 0.8438\n",
      "Epoch 200/300\n",
      "1440/1440 [==============================] - 0s 119us/sample - loss: 0.7885 - accuracy: 0.8201 - val_loss: 0.7590 - val_accuracy: 0.8438\n",
      "Epoch 201/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.7860 - accuracy: 0.8028 - val_loss: 0.7614 - val_accuracy: 0.7875\n",
      "Epoch 202/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 0.7823 - accuracy: 0.8174 - val_loss: 0.7574 - val_accuracy: 0.7937\n",
      "Epoch 203/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 0.7796 - accuracy: 0.8049 - val_loss: 0.7477 - val_accuracy: 0.7937\n",
      "Epoch 204/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 0.7795 - accuracy: 0.7889 - val_loss: 0.7437 - val_accuracy: 0.8188\n",
      "Epoch 205/300\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 0.7698 - accuracy: 0.80 - 0s 133us/sample - loss: 0.7712 - accuracy: 0.8083 - val_loss: 0.7456 - val_accuracy: 0.8250\n",
      "Epoch 206/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.7664 - accuracy: 0.7931 - val_loss: 0.7455 - val_accuracy: 0.8000\n",
      "Epoch 207/300\n",
      "1440/1440 [==============================] - 0s 130us/sample - loss: 0.7607 - accuracy: 0.8153 - val_loss: 0.7389 - val_accuracy: 0.8000\n",
      "Epoch 208/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 0.7551 - accuracy: 0.8264 - val_loss: 0.7347 - val_accuracy: 0.8438\n",
      "Epoch 209/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 0.7510 - accuracy: 0.8194 - val_loss: 0.7288 - val_accuracy: 0.8188\n",
      "Epoch 210/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.7514 - accuracy: 0.8194 - val_loss: 0.7355 - val_accuracy: 0.7812\n",
      "Epoch 211/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 0.7429 - accuracy: 0.8326 - val_loss: 0.7205 - val_accuracy: 0.8687\n",
      "Epoch 212/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.7419 - accuracy: 0.8090 - val_loss: 0.7254 - val_accuracy: 0.8250\n",
      "Epoch 213/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 0.7401 - accuracy: 0.8076 - val_loss: 0.7161 - val_accuracy: 0.8125\n",
      "Epoch 214/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 0.7308 - accuracy: 0.8257 - val_loss: 0.7106 - val_accuracy: 0.8500\n",
      "Epoch 215/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.7279 - accuracy: 0.8146 - val_loss: 0.7064 - val_accuracy: 0.8313\n",
      "Epoch 216/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 0.7259 - accuracy: 0.8139 - val_loss: 0.7116 - val_accuracy: 0.7563\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 142us/sample - loss: 0.7201 - accuracy: 0.8181 - val_loss: 0.6910 - val_accuracy: 0.8438\n",
      "Epoch 218/300\n",
      "1440/1440 [==============================] - 0s 128us/sample - loss: 0.7128 - accuracy: 0.8326 - val_loss: 0.7009 - val_accuracy: 0.8250\n",
      "Epoch 219/300\n",
      "1440/1440 [==============================] - 0s 135us/sample - loss: 0.7124 - accuracy: 0.8313 - val_loss: 0.6863 - val_accuracy: 0.8375\n",
      "Epoch 220/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 0.7091 - accuracy: 0.8167 - val_loss: 0.6786 - val_accuracy: 0.8188\n",
      "Epoch 221/300\n",
      "1440/1440 [==============================] - 0s 137us/sample - loss: 0.7131 - accuracy: 0.8000 - val_loss: 0.6864 - val_accuracy: 0.8375\n",
      "Epoch 222/300\n",
      "1440/1440 [==============================] - 0s 127us/sample - loss: 0.7031 - accuracy: 0.8181 - val_loss: 0.6828 - val_accuracy: 0.8687\n",
      "Epoch 223/300\n",
      "1440/1440 [==============================] - 0s 126us/sample - loss: 0.7035 - accuracy: 0.8153 - val_loss: 0.6773 - val_accuracy: 0.7875\n",
      "Epoch 224/300\n",
      "1440/1440 [==============================] - 0s 142us/sample - loss: 0.6934 - accuracy: 0.8285 - val_loss: 0.6655 - val_accuracy: 0.8813\n",
      "Epoch 225/300\n",
      "1440/1440 [==============================] - 0s 157us/sample - loss: 0.6891 - accuracy: 0.8604 - val_loss: 0.6684 - val_accuracy: 0.8250\n",
      "Epoch 226/300\n",
      "1440/1440 [==============================] - 0s 147us/sample - loss: 0.6868 - accuracy: 0.8299 - val_loss: 0.6599 - val_accuracy: 0.8625\n",
      "Epoch 227/300\n",
      "1440/1440 [==============================] - 0s 155us/sample - loss: 0.6816 - accuracy: 0.8278 - val_loss: 0.6679 - val_accuracy: 0.8062\n",
      "Epoch 228/300\n",
      "1440/1440 [==============================] - 0s 136us/sample - loss: 0.6781 - accuracy: 0.8438 - val_loss: 0.6630 - val_accuracy: 0.8687\n",
      "Epoch 229/300\n",
      "1440/1440 [==============================] - 0s 155us/sample - loss: 0.6745 - accuracy: 0.8625 - val_loss: 0.6611 - val_accuracy: 0.8500\n",
      "Epoch 230/300\n",
      "1440/1440 [==============================] - 0s 165us/sample - loss: 0.6698 - accuracy: 0.8215 - val_loss: 0.6524 - val_accuracy: 0.8062\n",
      "Epoch 231/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.6674 - accuracy: 0.8222 - val_loss: 0.6472 - val_accuracy: 0.8438\n",
      "Epoch 232/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 0.6678 - accuracy: 0.8181 - val_loss: 0.6436 - val_accuracy: 0.8562\n",
      "Epoch 233/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 0.6636 - accuracy: 0.8139 - val_loss: 0.6443 - val_accuracy: 0.8062\n",
      "Epoch 234/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 0.6539 - accuracy: 0.8382 - val_loss: 0.6490 - val_accuracy: 0.8500\n",
      "Epoch 235/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.6548 - accuracy: 0.8424 - val_loss: 0.6310 - val_accuracy: 0.8625\n",
      "Epoch 236/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.6518 - accuracy: 0.8264 - val_loss: 0.6337 - val_accuracy: 0.8500\n",
      "Epoch 237/300\n",
      "1440/1440 [==============================] - 0s 115us/sample - loss: 0.6448 - accuracy: 0.8438 - val_loss: 0.6243 - val_accuracy: 0.9062\n",
      "Epoch 238/300\n",
      "1440/1440 [==============================] - 0s 117us/sample - loss: 0.6424 - accuracy: 0.8458 - val_loss: 0.6320 - val_accuracy: 0.7875\n",
      "Epoch 239/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.6366 - accuracy: 0.8382 - val_loss: 0.6215 - val_accuracy: 0.8938\n",
      "Epoch 240/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.6346 - accuracy: 0.8347 - val_loss: 0.6306 - val_accuracy: 0.8375\n",
      "Epoch 241/300\n",
      "1440/1440 [==============================] - 0s 122us/sample - loss: 0.6344 - accuracy: 0.8299 - val_loss: 0.6131 - val_accuracy: 0.8438\n",
      "Epoch 242/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.6286 - accuracy: 0.8194 - val_loss: 0.6063 - val_accuracy: 0.8625\n",
      "Epoch 243/300\n",
      "1440/1440 [==============================] - 0s 111us/sample - loss: 0.6247 - accuracy: 0.8556 - val_loss: 0.6080 - val_accuracy: 0.8562\n",
      "Epoch 244/300\n",
      "1440/1440 [==============================] - 0s 109us/sample - loss: 0.6211 - accuracy: 0.8514 - val_loss: 0.6114 - val_accuracy: 0.8562\n",
      "Epoch 245/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.6185 - accuracy: 0.8340 - val_loss: 0.6019 - val_accuracy: 0.8375\n",
      "Epoch 246/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 0.6135 - accuracy: 0.8354 - val_loss: 0.6162 - val_accuracy: 0.8000\n",
      "Epoch 247/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.6153 - accuracy: 0.8382 - val_loss: 0.5977 - val_accuracy: 0.8375\n",
      "Epoch 248/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.6102 - accuracy: 0.8451 - val_loss: 0.5924 - val_accuracy: 0.8313\n",
      "Epoch 249/300\n",
      "1440/1440 [==============================] - 0s 107us/sample - loss: 0.6045 - accuracy: 0.8632 - val_loss: 0.5907 - val_accuracy: 0.8438\n",
      "Epoch 250/300\n",
      "1440/1440 [==============================] - 0s 103us/sample - loss: 0.6038 - accuracy: 0.8361 - val_loss: 0.5834 - val_accuracy: 0.8375\n",
      "Epoch 251/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 0.6065 - accuracy: 0.8354 - val_loss: 0.5964 - val_accuracy: 0.8500\n",
      "Epoch 252/300\n",
      "1440/1440 [==============================] - 0s 135us/sample - loss: 0.6000 - accuracy: 0.8576 - val_loss: 0.5854 - val_accuracy: 0.8250\n",
      "Epoch 253/300\n",
      "1440/1440 [==============================] - 0s 123us/sample - loss: 0.5950 - accuracy: 0.8444 - val_loss: 0.5836 - val_accuracy: 0.8500\n",
      "Epoch 254/300\n",
      "1440/1440 [==============================] - 0s 153us/sample - loss: 0.5886 - accuracy: 0.8576 - val_loss: 0.5654 - val_accuracy: 0.8750\n",
      "Epoch 255/300\n",
      "1440/1440 [==============================] - 0s 150us/sample - loss: 0.5903 - accuracy: 0.8403 - val_loss: 0.5734 - val_accuracy: 0.8500\n",
      "Epoch 256/300\n",
      "1440/1440 [==============================] - 0s 155us/sample - loss: 0.5851 - accuracy: 0.8639 - val_loss: 0.5669 - val_accuracy: 0.8562\n",
      "Epoch 257/300\n",
      "1440/1440 [==============================] - 0s 158us/sample - loss: 0.5794 - accuracy: 0.8653 - val_loss: 0.5818 - val_accuracy: 0.8375\n",
      "Epoch 258/300\n",
      "1440/1440 [==============================] - 0s 166us/sample - loss: 0.5782 - accuracy: 0.8299 - val_loss: 0.5685 - val_accuracy: 0.8375\n",
      "Epoch 259/300\n",
      "1440/1440 [==============================] - 0s 136us/sample - loss: 0.5761 - accuracy: 0.8528 - val_loss: 0.5571 - val_accuracy: 0.8313\n",
      "Epoch 260/300\n",
      "1440/1440 [==============================] - 0s 146us/sample - loss: 0.5754 - accuracy: 0.8604 - val_loss: 0.5543 - val_accuracy: 0.8375\n",
      "Epoch 261/300\n",
      "1440/1440 [==============================] - 0s 146us/sample - loss: 0.5703 - accuracy: 0.8625 - val_loss: 0.5604 - val_accuracy: 0.8500\n",
      "Epoch 262/300\n",
      "1440/1440 [==============================] - 0s 138us/sample - loss: 0.5691 - accuracy: 0.8542 - val_loss: 0.5496 - val_accuracy: 0.8562\n",
      "Epoch 263/300\n",
      "1440/1440 [==============================] - 0s 118us/sample - loss: 0.5682 - accuracy: 0.8514 - val_loss: 0.5441 - val_accuracy: 0.8438\n",
      "Epoch 264/300\n",
      "1440/1440 [==============================] - 0s 138us/sample - loss: 0.5657 - accuracy: 0.8542 - val_loss: 0.5481 - val_accuracy: 0.8625\n",
      "Epoch 265/300\n",
      "1440/1440 [==============================] - 0s 140us/sample - loss: 0.5601 - accuracy: 0.8590 - val_loss: 0.5451 - val_accuracy: 0.8813\n",
      "Epoch 266/300\n",
      "1440/1440 [==============================] - 0s 145us/sample - loss: 0.5587 - accuracy: 0.8375 - val_loss: 0.5324 - val_accuracy: 0.8625\n",
      "Epoch 267/300\n",
      "1440/1440 [==============================] - 0s 156us/sample - loss: 0.5545 - accuracy: 0.8458 - val_loss: 0.5407 - val_accuracy: 0.8562\n",
      "Epoch 268/300\n",
      "1440/1440 [==============================] - 0s 161us/sample - loss: 0.5506 - accuracy: 0.8639 - val_loss: 0.5256 - val_accuracy: 0.8500\n",
      "Epoch 269/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 0.5509 - accuracy: 0.8361 - val_loss: 0.5409 - val_accuracy: 0.8438\n",
      "Epoch 270/300\n",
      "1440/1440 [==============================] - 0s 124us/sample - loss: 0.5485 - accuracy: 0.8472 - val_loss: 0.5249 - val_accuracy: 0.8938\n",
      "Epoch 271/300\n",
      "1440/1440 [==============================] - 0s 120us/sample - loss: 0.5461 - accuracy: 0.8368 - val_loss: 0.5287 - val_accuracy: 0.8938\n",
      "Epoch 272/300\n",
      "1440/1440 [==============================] - 0s 138us/sample - loss: 0.5455 - accuracy: 0.8347 - val_loss: 0.5311 - val_accuracy: 0.8188\n",
      "Epoch 273/300\n",
      "1440/1440 [==============================] - 0s 138us/sample - loss: 0.5377 - accuracy: 0.8618 - val_loss: 0.5330 - val_accuracy: 0.8062\n",
      "Epoch 274/300\n",
      "1440/1440 [==============================] - 0s 142us/sample - loss: 0.5357 - accuracy: 0.8514 - val_loss: 0.5402 - val_accuracy: 0.8438\n",
      "Epoch 275/300\n",
      "1440/1440 [==============================] - 0s 156us/sample - loss: 0.5344 - accuracy: 0.8681 - val_loss: 0.5199 - val_accuracy: 0.8813\n",
      "Epoch 276/300\n",
      "1440/1440 [==============================] - 0s 164us/sample - loss: 0.5320 - accuracy: 0.8569 - val_loss: 0.5133 - val_accuracy: 0.8875\n",
      "Epoch 277/300\n",
      "1440/1440 [==============================] - 0s 160us/sample - loss: 0.5292 - accuracy: 0.8792 - val_loss: 0.5115 - val_accuracy: 0.8375\n",
      "Epoch 278/300\n",
      "1440/1440 [==============================] - 0s 149us/sample - loss: 0.5266 - accuracy: 0.8507 - val_loss: 0.5220 - val_accuracy: 0.8625\n",
      "Epoch 279/300\n",
      "1440/1440 [==============================] - 0s 150us/sample - loss: 0.5323 - accuracy: 0.8479 - val_loss: 0.5176 - val_accuracy: 0.8375\n",
      "Epoch 280/300\n",
      "1440/1440 [==============================] - 0s 153us/sample - loss: 0.5241 - accuracy: 0.8458 - val_loss: 0.5142 - val_accuracy: 0.8938\n",
      "Epoch 281/300\n",
      "1440/1440 [==============================] - 0s 150us/sample - loss: 0.5198 - accuracy: 0.8813 - val_loss: 0.5030 - val_accuracy: 0.8813\n",
      "Epoch 282/300\n",
      "1440/1440 [==============================] - 0s 140us/sample - loss: 0.5192 - accuracy: 0.8528 - val_loss: 0.4999 - val_accuracy: 0.8625\n",
      "Epoch 283/300\n",
      "1440/1440 [==============================] - 0s 139us/sample - loss: 0.5121 - accuracy: 0.8847 - val_loss: 0.5117 - val_accuracy: 0.8375\n",
      "Epoch 284/300\n",
      "1440/1440 [==============================] - 0s 125us/sample - loss: 0.5106 - accuracy: 0.8618 - val_loss: 0.4951 - val_accuracy: 0.8687\n",
      "Epoch 285/300\n",
      "1440/1440 [==============================] - 0s 144us/sample - loss: 0.5109 - accuracy: 0.8722 - val_loss: 0.5014 - val_accuracy: 0.9062\n",
      "Epoch 286/300\n",
      "1440/1440 [==============================] - 0s 121us/sample - loss: 0.5098 - accuracy: 0.8542 - val_loss: 0.4943 - val_accuracy: 0.8750\n",
      "Epoch 287/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.5045 - accuracy: 0.8708 - val_loss: 0.4953 - val_accuracy: 0.8813\n",
      "Epoch 288/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.5121 - accuracy: 0.8597 - val_loss: 0.4887 - val_accuracy: 0.8813\n",
      "Epoch 289/300\n",
      "1440/1440 [==============================] - 0s 107us/sample - loss: 0.5007 - accuracy: 0.8729 - val_loss: 0.4877 - val_accuracy: 0.8562\n",
      "Epoch 290/300\n",
      "1440/1440 [==============================] - 0s 106us/sample - loss: 0.5019 - accuracy: 0.8521 - val_loss: 0.4856 - val_accuracy: 0.8938\n",
      "Epoch 291/300\n",
      "1440/1440 [==============================] - 0s 108us/sample - loss: 0.4978 - accuracy: 0.8681 - val_loss: 0.4901 - val_accuracy: 0.8375\n",
      "Epoch 292/300\n",
      "1440/1440 [==============================] - 0s 113us/sample - loss: 0.4924 - accuracy: 0.8868 - val_loss: 0.4817 - val_accuracy: 0.8625\n",
      "Epoch 293/300\n",
      "1440/1440 [==============================] - 0s 108us/sample - loss: 0.4946 - accuracy: 0.8639 - val_loss: 0.4850 - val_accuracy: 0.9000\n",
      "Epoch 294/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.4915 - accuracy: 0.8799 - val_loss: 0.4775 - val_accuracy: 0.8562\n",
      "Epoch 295/300\n",
      "1440/1440 [==============================] - 0s 116us/sample - loss: 0.4873 - accuracy: 0.8854 - val_loss: 0.4789 - val_accuracy: 0.8687\n",
      "Epoch 296/300\n",
      "1440/1440 [==============================] - 0s 105us/sample - loss: 0.4909 - accuracy: 0.8715 - val_loss: 0.4815 - val_accuracy: 0.8375\n",
      "Epoch 297/300\n",
      "1440/1440 [==============================] - 0s 98us/sample - loss: 0.4804 - accuracy: 0.8681 - val_loss: 0.4813 - val_accuracy: 0.8438\n",
      "Epoch 298/300\n",
      "1440/1440 [==============================] - 0s 114us/sample - loss: 0.4868 - accuracy: 0.8674 - val_loss: 0.4677 - val_accuracy: 0.9187\n",
      "Epoch 299/300\n",
      "1440/1440 [==============================] - 0s 112us/sample - loss: 0.4787 - accuracy: 0.8965 - val_loss: 0.4684 - val_accuracy: 0.8562\n",
      "Epoch 300/300\n",
      "1440/1440 [==============================] - 0s 100us/sample - loss: 0.4825 - accuracy: 0.8701 - val_loss: 0.4732 - val_accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "#convert the labels into the one-hot format\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "\n",
    "#initialize model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#add input layer\n",
    "#the first two layers will each have 80 units with the tanh activation\n",
    "#the last layer (output layer) will have 20 ayers for the 20 class labels\n",
    "#uses softmax to give probability of each class. \n",
    "\n",
    "model.add(keras.layers.Dense(units=80, input_dim=X_trainc.shape[1], \n",
    "                             kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', \n",
    "                             activation='relu'))\n",
    "model.add(keras.layers.Dense(units=80, input_dim=80, \n",
    "                             kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', \n",
    "                             activation='relu'))\n",
    "#add output layer\n",
    "model.add(keras.layers.Dense(units=20, input_dim=y_train_onehot.shape[1], \n",
    "                             kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', \n",
    "                             activation='softmax'))\n",
    "#stochastic gradient optimizer\n",
    "sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "history = model.fit(X_trainc, y_train_onehot, batch_size=40,\n",
    "                    epochs=300, verbose=1, validation_split=0.1)\n",
    "\n",
    "\n",
    "#Goal: test accuracy of 85% achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  89.75\n",
      "Test accuracy:  88.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating the training accuracy\n",
    "y_train_pred = model.predict_classes(X_trainc, verbose=0)\n",
    "count_pred = np.sum(y_train == y_train_pred, axis=0)\n",
    "accuracy_train = (count_pred/y_train.shape[0])*100\n",
    "print('Training accuracy: ', accuracy_train)\n",
    "\n",
    "#Calculating the testing accuracy\n",
    "y_test_pred = model.predict_classes(X_testc, verbose=0)\n",
    "count_pred = np.sum(y_test == y_test_pred, axis=0)\n",
    "accuracy_test = (count_pred/y_test.shape[0])*100\n",
    "print('Test accuracy: ', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
